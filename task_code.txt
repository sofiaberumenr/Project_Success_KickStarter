## Task 1 – Classification Model

### Prepare Data for Classification

# Encode categorical variables
from sklearn.preprocessing import LabelEncoder

# Create copies for encoding
X_train = df_oct.drop(columns=['state', 'state_binary']).copy()
y_train = df_oct['state_binary'].copy()

X_test = df_nov.drop(columns=['state', 'state_binary']).copy()
y_test = df_nov['state_binary'].copy()

# Identify categorical columns
categorical_cols = X_train.select_dtypes(include=['object', 'bool']).columns.tolist()
print(f"Categorical columns: {categorical_cols}")

# Label encode categorical variables
label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    X_train[col] = le.fit_transform(X_train[col].astype(str))
    X_test[col] = le.transform(X_test[col].astype(str))
    label_encoders[col] = le

print(f"\nX_train shape: {X_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"y_train distribution:\n{y_train.value_counts()}")
print(f"y_test distribution:\n{y_test.value_counts()}")

### Scale Features

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("Features scaled successfully")

### 1. Logistic Regression

from sklearn.linear_model import LogisticRegression

lr_model = LogisticRegression(max_iter=1000, random_state=42)
lr_model.fit(X_train_scaled, y_train)

y_pred_lr = lr_model.predict(X_test_scaled)
y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]

print("=== Logistic Regression ===")
print(f"Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_lr):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_lr):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_lr):.4f}")
print(f"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_lr):.4f}")
print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred_lr))

### 2. Decision Tree

dt_model = DecisionTreeClassifier(max_depth=10, random_state=42)
dt_model.fit(X_train, y_train)

y_pred_dt = dt_model.predict(X_test)
y_pred_proba_dt = dt_model.predict_proba(X_test)[:, 1]

print("\n=== Decision Tree ===")
print(f"Accuracy: {accuracy_score(y_test, y_pred_dt):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_dt):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_dt):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_dt):.4f}")
print(f"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_dt):.4f}")

### 3. Random Forest

rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)
rf_model.fit(X_train, y_train)

y_pred_rf = rf_model.predict(X_test)
y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]

print("\n=== Random Forest ===")
print(f"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_rf):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_rf):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_rf):.4f}")
print(f"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_rf):.4f}")

# Feature importance
feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\nTop 10 Important Features:")
print(feature_importance.head(10))

### 4. Gradient Boosting

gb_model = GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42)
gb_model.fit(X_train, y_train)

y_pred_gb = gb_model.predict(X_test)
y_pred_proba_gb = gb_model.predict_proba(X_test)[:, 1]

print("\n=== Gradient Boosting ===")
print(f"Accuracy: {accuracy_score(y_test, y_pred_gb):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_gb):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_gb):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_gb):.4f}")
print(f"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_gb):.4f}")

### 5. K-Nearest Neighbors

knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train_scaled, y_train)

y_pred_knn = knn_model.predict(X_test_scaled)
y_pred_proba_knn = knn_model.predict_proba(X_test_scaled)[:, 1]

print("\n=== K-Nearest Neighbors ===")
print(f"Accuracy: {accuracy_score(y_test, y_pred_knn):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_knn):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_knn):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_knn):.4f}")
print(f"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_knn):.4f}")

### 6. Support Vector Machine

svm_model = SVC(kernel='rbf', probability=True, random_state=42)
# Use a sample for faster training
sample_size = min(10000, len(X_train_scaled))
sample_idx = np.random.choice(len(X_train_scaled), sample_size, replace=False)
svm_model.fit(X_train_scaled[sample_idx], y_train.iloc[sample_idx])

y_pred_svm = svm_model.predict(X_test_scaled)
y_pred_proba_svm = svm_model.predict_proba(X_test_scaled)[:, 1]

print("\n=== Support Vector Machine ===")
print(f"Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_svm):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_svm):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_svm):.4f}")
print(f"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_svm):.4f}")

### 7. Naive Bayes

from sklearn.naive_bayes import GaussianNB

nb_model = GaussianNB()
nb_model.fit(X_train_scaled, y_train)

y_pred_nb = nb_model.predict(X_test_scaled)
y_pred_proba_nb = nb_model.predict_proba(X_test_scaled)[:, 1]

print("\n=== Naive Bayes ===")
print(f"Accuracy: {accuracy_score(y_test, y_pred_nb):.4f}")
print(f"Precision: {precision_score(y_test, y_pred_nb):.4f}")
print(f"Recall: {recall_score(y_test, y_pred_nb):.4f}")
print(f"F1-Score: {f1_score(y_test, y_pred_nb):.4f}")
print(f"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_nb):.4f}")

### Model Comparison

results = pd.DataFrame({
    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 
              'Gradient Boosting', 'KNN', 'SVM', 'Naive Bayes'],
    'Accuracy': [accuracy_score(y_test, y_pred_lr), accuracy_score(y_test, y_pred_dt),
                 accuracy_score(y_test, y_pred_rf), accuracy_score(y_test, y_pred_gb),
                 accuracy_score(y_test, y_pred_knn), accuracy_score(y_test, y_pred_svm),
                 accuracy_score(y_test, y_pred_nb)],
    'Precision': [precision_score(y_test, y_pred_lr), precision_score(y_test, y_pred_dt),
                  precision_score(y_test, y_pred_rf), precision_score(y_test, y_pred_gb),
                  precision_score(y_test, y_pred_knn), precision_score(y_test, y_pred_svm),
                  precision_score(y_test, y_pred_nb)],
    'Recall': [recall_score(y_test, y_pred_lr), recall_score(y_test, y_pred_dt),
               recall_score(y_test, y_pred_rf), recall_score(y_test, y_pred_gb),
               recall_score(y_test, y_pred_knn), recall_score(y_test, y_pred_svm),
               recall_score(y_test, y_pred_nb)],
    'F1-Score': [f1_score(y_test, y_pred_lr), f1_score(y_test, y_pred_dt),
                 f1_score(y_test, y_pred_rf), f1_score(y_test, y_pred_gb),
                 f1_score(y_test, y_pred_knn), f1_score(y_test, y_pred_svm),
                 f1_score(y_test, y_pred_nb)],
    'ROC-AUC': [roc_auc_score(y_test, y_pred_proba_lr), roc_auc_score(y_test, y_pred_proba_dt),
                roc_auc_score(y_test, y_pred_proba_rf), roc_auc_score(y_test, y_pred_proba_gb),
                roc_auc_score(y_test, y_pred_proba_knn), roc_auc_score(y_test, y_pred_proba_svm),
                roc_auc_score(y_test, y_pred_proba_nb)]
})

print("\n=== Model Comparison ===")
print(results.sort_values('ROC-AUC', ascending=False))

# Visualize comparison
fig, axes = plt.subplots(1, 2, figsize=(15, 5))

results.plot(x='Model', y=['Accuracy', 'Precision', 'Recall', 'F1-Score'], 
             kind='bar', ax=axes[0], rot=45)
axes[0].set_title('Model Performance Metrics')
axes[0].set_ylabel('Score')
axes[0].legend(loc='lower right')

results.plot(x='Model', y='ROC-AUC', kind='bar', ax=axes[1], rot=45, color='coral')
axes[1].set_title('ROC-AUC Scores')
axes[1].set_ylabel('ROC-AUC')
axes[1].axhline(y=0.5, color='red', linestyle='--', label='Random Baseline')
axes[1].legend()

plt.tight_layout()
plt.show()

### ROC Curves

plt.figure(figsize=(10, 8))

models_roc = [
    ('Logistic Regression', y_pred_proba_lr),
    ('Random Forest', y_pred_proba_rf),
    ('Gradient Boosting', y_pred_proba_gb),
    ('KNN', y_pred_proba_knn),
    ('SVM', y_pred_proba_svm),
    ('Naive Bayes', y_pred_proba_nb)
]

for name, y_proba in models_roc:
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    auc = roc_auc_score(y_test, y_proba)
    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})')

plt.plot([0, 1], [0, 1], 'k--', label='Random Baseline')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves - Classification Models')
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

## Task 2 – Clustering Model

### Prepare Data for Clustering

# Use scaled features without target variable
X_clustering = X_train_scaled.copy()

# Sample for faster clustering (optional)
sample_size = min(20000, len(X_clustering))
sample_idx = np.random.choice(len(X_clustering), sample_size, replace=False)
X_sample = X_clustering[sample_idx]

print(f"Clustering on {len(X_sample)} samples")

### 1. K-Means Clustering

# Elbow method to find optimal k
inertias = []
silhouette_scores = []
K_range = range(2, 11)

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(X_sample)
    inertias.append(kmeans.inertia_)
    silhouette_scores.append(silhouette_score(X_sample, kmeans.labels_))

# Plot elbow curve
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

axes[0].plot(K_range, inertias, 'bo-')
axes[0].set_xlabel('Number of Clusters (k)')
axes[0].set_ylabel('Inertia')
axes[0].set_title('Elbow Method')
axes[0].grid(alpha=0.3)

axes[1].plot(K_range, silhouette_scores, 'ro-')
axes[1].set_xlabel('Number of Clusters (k)')
axes[1].set_ylabel('Silhouette Score')
axes[1].set_title('Silhouette Score vs K')
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.show()

# Fit K-Means with optimal k
optimal_k = 4  # Adjust based on elbow plot
kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
kmeans_labels = kmeans_final.fit_predict(X_sample)

print(f"\n=== K-Means Clustering (k={optimal_k}) ===")
print(f"Silhouette Score: {silhouette_score(X_sample, kmeans_labels):.4f}")
print(f"Davies-Bouldin Score: {davies_bouldin_score(X_sample, kmeans_labels):.4f}")
print(f"\nCluster Distribution:")
print(pd.Series(kmeans_labels).value_counts().sort_index())

### 2. Hierarchical Clustering

from scipy.cluster.hierarchy import dendrogram, linkage

# Use smaller sample for dendrogram
dendro_sample_size = min(1000, len(X_sample))
dendro_idx = np.random.choice(len(X_sample), dendro_sample_size, replace=False)
X_dendro = X_sample[dendro_idx]

# Compute linkage
linkage_matrix = linkage(X_dendro, method='ward')

# Plot dendrogram
plt.figure(figsize=(12, 6))
dendrogram(linkage_matrix, truncate_mode='lastp', p=30)
plt.title('Hierarchical Clustering Dendrogram')
plt.xlabel('Cluster Size')
plt.ylabel('Distance')
plt.tight_layout()
plt.show()

# Fit hierarchical clustering
hierarchical = AgglomerativeClustering(n_clusters=optimal_k)
hierarchical_labels = hierarchical.fit_predict(X_sample)

print(f"\n=== Hierarchical Clustering (k={optimal_k}) ===")
print(f"Silhouette Score: {silhouette_score(X_sample, hierarchical_labels):.4f}")
print(f"Davies-Bouldin Score: {davies_bouldin_score(X_sample, hierarchical_labels):.4f}")
print(f"\nCluster Distribution:")
print(pd.Series(hierarchical_labels).value_counts().sort_index())

### 3. PCA for Visualization

pca = PCA(n_components=2, random_state=42)
X_pca = pca.fit_transform(X_sample)

print(f"\n=== PCA ===")
print(f"Explained Variance Ratio: {pca.explained_variance_ratio_}")
print(f"Total Variance Explained: {pca.explained_variance_ratio_.sum():.4f}")

# Visualize clusters in PCA space
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# K-Means clusters
scatter1 = axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans_labels, 
                           cmap='viridis', alpha=0.6, s=20)
axes[0].set_title(f'K-Means Clustering (k={optimal_k}) - PCA Visualization')
axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')
axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')
plt.colorbar(scatter1, ax=axes[0], label='Cluster')

# Hierarchical clusters
scatter2 = axes[1].scatter(X_pca[:, 0], X_pca[:, 1], c=hierarchical_labels, 
                           cmap='plasma', alpha=0.6, s=20)
axes[1].set_title(f'Hierarchical Clustering (k={optimal_k}) - PCA Visualization')
axes[1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')
axes[1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')
plt.colorbar(scatter2, ax=axes[1], label='Cluster')

plt.tight_layout()
plt.show()

### Cluster Characteristics Analysis

# Add cluster labels to original data
df_clustered = df_oct.iloc[sample_idx].copy()
df_clustered['kmeans_cluster'] = kmeans_labels
df_clustered['hierarchical_cluster'] = hierarchical_labels

# Analyze K-Means clusters
print("\n=== K-Means Cluster Characteristics ===")
for cluster in range(optimal_k):
    cluster_data = df_clustered[df_clustered['kmeans_cluster'] == cluster]
    print(f"\nCluster {cluster} (n={len(cluster_data)}):")
    print(f"  Success Rate: {(cluster_data['state'] == 'successful').mean():.2%}")
    if 'goal_usd' in cluster_data.columns:
        print(f"  Avg Goal (USD): ${cluster_data['goal_usd'].mean():,.2f}")
    if 'duration_days' in cluster_data.columns:
        print(f"  Avg Duration: {cluster_data['duration_days'].mean():.1f} days")
    if 'staff_pick' in cluster_data.columns:
        print(f"  Staff Pick Rate: {cluster_data['staff_pick'].mean():.2%}")
    if 'main_category' in cluster_data.columns:
        print(f"  Top Category: {cluster_data['main_category'].mode()[0] if len(cluster_data['main_category'].mode()) > 0 else 'N/A'}")

### Clustering Summary

clustering_results = pd.DataFrame({
    'Method': ['K-Means', 'Hierarchical'],
    'Silhouette Score': [
        silhouette_score(X_sample, kmeans_labels),
        silhouette_score(X_sample, hierarchical_labels)
    ],
    'Davies-Bouldin Score': [
        davies_bouldin_score(X_sample, kmeans_labels),
        davies_bouldin_score(X_sample, hierarchical_labels)
    ]
})

print("\n=== Clustering Method Comparison ===")
print(clustering_results)
